# -*- coding: utf-8 -*-
"""Atividade 19/06/2025 - Do Notebook ao Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z2Z31v2Y43PCN-_S0_yhE9nNPPtcIrJa
"""

import requests

# SELIC acumulada em 12 meses
resp = requests.get("https://api.bcb.gov.br/dados/serie/bcdata.sgs.4390/dados/ultimos/12?formato=json")
print(resp.json())

url = "https://api.bcb.gov.br/dados/serie/bcdata.sgs.4390/dados?formato=json&dataInicial=12/06/2025&dataFinal=19/06/2025"
resp = requests.get(url)
print(resp.json())

# prompt: gera um codigo que vai pegar os dados da queres
# url = "https://api.bcb.gov.br/dados/serie/bcdata.sgs.1/dados?formato=json&dataInicial=12/06/2025&dataFinal=19/06/2025"
# resp = requests.get(url)
# print(resp.json())
# e sepre pegar os dados d-1
# ele vai rodar todo dia as 05 da manhã

from datetime import datetime, timedelta
import requests

# Função para obter a data de ontem no formato DD/MM/YYYY
def get_yesterday_date():
    yesterday = datetime.now() - timedelta(days=1)
    return yesterday.strftime('%d/%m/%Y')

# Obter a data de ontem
yesterday_str = get_yesterday_date()

# Construir a URL com a data de ontem para dataInicial e dataFinal
url_d_minus_1 = f"https://api.bcb.gov.br/dados/serie/bcdata.sgs.1/dados?formato=json&dataInicial={yesterday_str}&dataFinal={yesterday_str}"

# Fazer a requisição para a data de ontem
resp_d_minus_1 = requests.get(url_d_minus_1)

# Imprimir os dados (se a requisição for bem-sucedida)
if resp_d_minus_1.status_code == 200:
    data_d_minus_1 = resp_d_minus_1.json()
    print(f"Dados da Queres para {yesterday_str}:")
    print(data_d_minus_1)
else:
    print(f"Erro ao obter dados para {yesterday_str}. Status code: {resp_d_minus_1.status_code}")
resp_d_minus_1.text

# Para rodar todo dia às 05 da manhã, você precisaria agendar a execução deste script
# usando ferramentas externas como cron (em sistemas baseados em Linux/macOS)
# ou o Agendador de Tarefas (em Windows). O código Python em si não controla o agendamento.

# prompt: agora use a biblioteca schedule e use pendulum para pegar horario de são paulo brasil

!pip install schedule pendulum

import schedule
import pendulum
import time
import requests
from datetime import datetime, timedelta

# Your existing functions
def get_yesterday_date():
    yesterday = datetime.now() - timedelta(days=1)
    return yesterday.strftime('%d/%m/%Y')

def fetch_data():
    yesterday_str = get_yesterday_date()
    url_d_minus_1 = f"https://api.bcb.gov.br/dados/serie/bcdata.sgs.1/dados?formato=json&dataInicial={yesterday_str}&dataFinal={yesterday_str}"
    resp_d_minus_1 = requests.get(url_d_minus_1)

    if resp_d_minus_1.status_code == 200:
        data_d_minus_1 = resp_d_minus_1.json()
        print(f"Dados da Queres para {yesterday_str}:")
        print(data_d_minus_1)
    else:
        print(f"Erro ao obter dados para {yesterday_str}. Status code: {resp_d_minus_1.status_code}")
    print(resp_d_minus_1.text)


# Schedule the task to run every day at 5:00 AM in São Paulo time
def schedule_task():
    sao_paulo_tz = pendulum.timezone('America/Sao_Paulo')
    schedule.every().day.at("05:00", sao_paulo_tz).do(fetch_data)

# You would typically run this scheduling in a long-running process
# For a Colab notebook, you can run it once and then theoretically keep the
# notebook running, but this is not a reliable way to run scheduled tasks
# in production. Colab notebooks are not designed for continuous execution.

schedule_task()

print("Task scheduled to run every day at 05:00 AM São Paulo time.")

# In a typical Python script, you would have a loop like this to keep the
# scheduler running. This loop is commented out because it would block the
# Colab notebook indefinitely.
#





#

"""Transforme o codigo a baixo em uma rotina usando schedule

+ para extrair os dados do dia 01/01/2023 até 01/01/2025 (extrair base bruta)

+ Ajuste para rodar o incrementar todo inicio de mes
"""

import requests
import pandas as pd
from datetime import datetime

# Indicadores e seus códigos SGS
series = {
    "selic_diaria": 11,         # diário → média mensal
    "selic_12m": 4390,          # mensal
    "ipca": 433,                # mensal
    "dolar": 1,                 # diário → média mensal
    "pib": 4380,                # trimestral
    "poupanca": 195             # mensal
}

# Período de coleta
data_inicial = "01/01/2020"
data_final = datetime.today().strftime("%d/%m/%Y")

def extrair_serie(nome, codigo):
    print(f"📡 Extraindo {nome} ({codigo})...")
    url = (
        f"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{codigo}/dados"
        f"?formato=json&dataInicial={data_inicial}&dataFinal={data_final}"
    )
    resp = requests.get(url)
    dados = resp.json()
    df = pd.DataFrame(dados)
    df["data"] = pd.to_datetime(df["data"], dayfirst=True)
    df["valor"] = pd.to_numeric(df["valor"].str.replace(",", "."), errors="coerce")
    df = df.rename(columns={"valor": nome})
    return df[["data", nome]]

# Extrai e agrega os dados mensalmente
def agregar_mensal(df, nome_coluna):
    df["ano_mes"] = df["data"].dt.to_period("M")
    return df.groupby("ano_mes")[nome_coluna].mean().reset_index()



# (Opcional) Exporta para CSV

def fetche_data():
  # Consolidação
  dfs_mensais = []

  for nome, codigo in series.items():
    df_raw = extrair_serie(nome, codigo)
    df_mensal = agregar_mensal(df_raw, nome)
    dfs_mensais.append(df_mensal)

  # Merge entre todos os indicadores por ano-mês
  consolidado = dfs_mensais[0]
  for df in dfs_mensais[1:]:
    consolidado = pd.merge(consolidado, df, on="ano_mes", how="outer")

  # Formata
  consolidado["ano_mes"] = consolidado["ano_mes"].astype(str)
  consolidado = consolidado.sort_values("ano_mes").reset_index(drop=True)

  # Exibe resultado
  print(consolidado.tail())

  periodo = f"{data_inicial} a {data_final}.csv".replace("/", "-")
  consolidado.to_csv(periodo, index=False)

fetche_data()

consolidado.to_csv("consolidado_mensal_bcb.csv", index=False)

consolidado

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import plotly.express as px
# import pandas as pd
# from datetime import date
# 
# # Configuração da página
# st.set_page_config(page_title="Dashboard Econômico", layout="wide")
# 
# 
# 
# st.title("📊 Dashboard Econômico: SELIC, IPCA e Dólar")
# 
# # Carrega dados
# df = pd.read_csv("consolidado_mensal_bcb.csv")
# df["ano_mes"] = pd.to_datetime(df["ano_mes"])
# df = df.sort_values("ano_mes")
# 
# # Filtro de data (intervalo)
# min_data = df["ano_mes"].min().date()
# max_data = df["ano_mes"].max().date()
# 
# col_ini, col_fim = st.columns(2)
# with col_ini:
#     data_inicio = st.date_input("📅 Data inicial", value=min_data, min_value=min_data, max_value=max_data)
# with col_fim:
#     data_fim = st.date_input("📅 Data final", value=max_data, min_value=min_data, max_value=max_data)
# 
# # Filtra o DataFrame com base nas datas
# df_filtrado = df[(df["ano_mes"] >= pd.to_datetime(data_inicio)) & (df["ano_mes"] <= pd.to_datetime(data_fim))]
# 
# # Validação: evita erro se o filtro retornar vazio
# if df_filtrado.empty:
#     st.warning("⚠️ Nenhum dado disponível para o intervalo selecionado.")
#     st.stop()
# 
# ultima_linha = df_filtrado.iloc[-1]
# ipca_valor = ultima_linha["ipca"]
# ipca_display = f"{ipca_valor:.2f}%" if pd.notna(ipca_valor) else "–"
# 
# # KPIs
# col1, col2, col3 = st.columns(3)
# col1.metric("📈 SELIC atual", f"{ultima_linha['selic_diaria']:.2f}%")
# col2.metric("📊 Inflação mensal (IPCA)", ipca_display)
# col3.metric("💵 Dólar médio", f"R$ {ultima_linha['dolar']:.2f}")
# 
# # Gráfico
# fig = px.line(
#     df_filtrado,
#     x="ano_mes",
#     y=["selic_diaria", "ipca"],
#     title="📉 Evolução mensal: SELIC vs. IPCA",
#     labels={"value": "Valor (%)", "ano_mes": "Data"},
# )
# 
# fig.update_layout(
#     template="plotly_dark",
#     legend=dict(orientation="h", x=0.5, xanchor="center"),
#     height=450,
#     margin=dict(t=50, l=20, r=20, b=40)
# )
# 
# st.plotly_chart(fig, use_container_width=True)
# 
# # Rodapé
# st.markdown("---")
# st.caption("Fonte dos dados: Banco Central do Brasil • Atualizado automaticamente")
#

!pip install streamlit pyngrok --quiet
!ngrok config add-authtoken 4vr1FettXnnxkpfdzihJF_7KK2ZbVeJzeXqi4h5ar4X

from pyngrok import ngrok

# Libera a porta do Streamlit (8501)
public_url = ngrok.connect(addr="8501", proto="http")


print(f"🔗 Acesse o app: {public_url}")

# Roda o Streamlit
!streamlit run app.py &>/dev/null &

